<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
    <title>GRAPHITE SKETCH AR</title>
    <style>
      :root{
        --brand:#0ea5e9;         /* primary */
        --accent:#f59e0b;        /* accent */
        --bg:#0b0b10;            /* neutral 1 */
        --fg:#e5e7eb;            /* neutral 2 */
        --muted:#9ca3af;         /* neutral 3 */
      }
      html,body{height:100%;background:var(--bg);color:var(--fg);margin:0;font-family:system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji","Segoe UI Emoji";}
      .app{position:fixed;inset:0;overflow:hidden;}
      video#camera{
        position:absolute; inset:0; width:100%; height:100%; object-fit:cover;
        transform:scaleX(-1); /* mirrored UX */
        background:#000;
      }
      /* UI */
      .hud{
        position:absolute; inset:0; pointer-events:none; display:flex; flex-direction:column; justify-content:space-between;
        padding:16px;
        background: radial-gradient(1200px 600px at 50% -10%, rgba(14,165,233,0.15), transparent 60%);
      }
      header{
        pointer-events:none; text-align:center; margin-top:8px;
      }
      .title{
        display:inline-block; font-weight:800; letter-spacing:0.04em; text-transform:uppercase;
        font-size: clamp(18px, 4.5vw, 28px); padding:8px 14px; border-radius:999px;
        background:rgba(14,165,233,0.18); border:1px solid rgba(14,165,233,0.35); color:#e6f6ff; text-shadow:0 1px 0 rgba(0,0,0,.4);
        box-shadow:0 0 24px rgba(14,165,233,0.25) inset, 0 8px 30px rgba(14,165,233,0.1);
      }
      .status{
        pointer-events:none; text-align:center; color:var(--muted); font-size:14px; margin:8px 0 0;
        text-shadow:0 1px 2px rgba(0,0,0,.5);
      }
      .controls{
        position:absolute; left:50%; bottom:20px; transform:translateX(-50%); display:flex; gap:12px; pointer-events:auto;
      }
      .btn{
        appearance:none; border:none; cursor:pointer;
        background:linear-gradient(180deg, rgba(14,165,233,0.85), rgba(14,165,233,0.55));
        color:#001219; font-weight:700; letter-spacing:.02em;
        padding:14px 18px; border-radius:12px; box-shadow: 0 10px 30px rgba(14,165,233,.35);
      }
      .btn:active{ transform:translateY(1px); }

      /* Guide frame while scanning */
      .guide{
        position:absolute; left:50%; top:50%; width:min(70vw, 360px); aspect-ratio:0.75; transform:translate(-50%,-50%);
        border:2px dashed rgba(229,231,235,.25); border-radius:12px;
      }

      /* AR overlay container anchored to match box */
      .ar-layer{
        position:absolute; left:0; top:0; pointer-events:none;
        will-change: transform, width, height, opacity; opacity:0; transition:opacity .35s ease;
      }
      .ar-layer.active{ opacity:1; }
      .gif-stack{
        position:absolute; inset:0; display:grid; grid-template-columns:1fr 1fr; grid-template-rows:1fr 1fr; gap:8px; padding:8px;
        mix-blend-mode:screen;
      }
      .gif-card{
        position:relative; border-radius:10px; overflow:hidden; background:rgba(245,158,11,.12);
        border:1px solid rgba(245,158,11,.35); box-shadow: 0 10px 40px rgba(245,158,11,.25);
      }
      canvas.gif{position:absolute; inset:0; width:100%; height:100%;}
      /* Make one big canvas spanning two cells to feel dynamic */
      .gif-card.big{ grid-column:1 / span 2; grid-row:1 / span 1; }

      /* End screen */
      .end{
        position:absolute; inset:0; display:none; place-items:center; background:rgba(0,0,0,.6); backdrop-filter: blur(6px);
      }
      .end.show{ display:grid; }
      .end .panel{
        background:linear-gradient(180deg, rgba(2,6,23,0.8), rgba(2,6,23,0.6));
        border:1px solid rgba(229,231,235,.14);
        box-shadow:0 30px 80px rgba(0,0,0,.5), inset 0 0 60px rgba(14,165,233,.08);
        color:var(--fg); padding:22px 24px; border-radius:16px; text-align:center; max-width:90vw;
      }
      .end h2{ margin:0 0 8px; font-size:20px; letter-spacing:.02em; }
      .end p{ margin:0 0 16px; color:var(--muted); font-size:14px; }
      .end .btn{ background:linear-gradient(180deg, rgba(245,158,11,0.9), rgba(245,158,11,0.6)); }

      /* Hidden working canvases */
      canvas#work, canvas#tmpl{ display:none; }

      /* Small sparkle when target locks */
      .spark{
        position:absolute; width:8px; height:8px; border-radius:999px; background:#fff;
        box-shadow:0 0 12px #fff, 0 0 30px var(--brand), 0 0 60px var(--accent);
        animation: pop .8s ease forwards;
      }
      @keyframes pop{
        0%{ transform:scale(.2); opacity:0; }
        40%{ transform:scale(1.6); opacity:1; }
        100%{ transform:scale(1); opacity:.0; }
      }
    </style>
  </head>
  <body>
    <div class="app" id="app">
       Camera 
      <video id="camera" muted playsinline autoplay></video>

       Hidden target reference image (for detection) 
      <img id="refImg" alt="Target reference" crossOrigin="anonymous"
           src="https://hebbkx1anhila5yf.public.blob.vercel-storage.com/image-NuVXrTuFsxHVBwJWfVMGwayZYMcrBv.png"
           style="position:absolute; left:-9999px; top:-9999px; width:320px; height:auto;" />

       UI HUD 
      <div class="hud">
        <header>
          <div class="title">Welcome to GRAPHITE SKETCH</div>
          <div class="status" id="status">Tap Start to allow back camera + audio. Then point at the reference image.</div>
        </header>
        <div class="guide" id="guide"></div>
        <div class="controls">
          <button class="btn" id="startBtn">Start AR</button>
          <button class="btn" id="stopBtn" style="display:none;">Stop</button>
        </div>
      </div>

       AR Overlay (anchored where the image is detected) 
      <div class="ar-layer" id="arLayer" aria-hidden="true">
        <div class="gif-stack">
          <div class="gif-card big"><canvas class="gif" id="gif1"></canvas></div>
          <div class="gif-card"><canvas class="gif" id="gif2"></canvas></div>
          <div class="gif-card"><canvas class="gif" id="gif3"></canvas></div>
        </div>
      </div>

       End Screen 
      <div class="end" id="end">
        <div class="panel">
          <h2>AR session ended</h2>
          <p>Thanks for exploring GRAPHITE SKETCH.</p>
          <button class="btn" id="restartBtn">Restart</button>
        </div>
      </div>

       Working canvases 
      <canvas id="work" width="320" height="240"></canvas>
      <canvas id="tmpl" width="120" height="160"></canvas>

       Background audio 
      <audio id="bgm" preload="auto">
         Replace with your music file 
        <source src="song.mp3" type="audio/mp4" />
      </audio>
    </div>

    <script>
      // ---- Utility: Speech greeting (optional, improves “say welcome” experience) ----
      function sayWelcome(){
        try{
          const u = new SpeechSynthesisUtterance("Welcome to Graphite Sketch");
          u.rate = 0.95; u.pitch = 1; u.lang = "en-US";
          speechSynthesis.cancel();
          speechSynthesis.speak(u);
        }catch(e){}
      }

      // ---- Camera setup (back camera) ----
      const video = document.getElementById('camera');
      const startBtn = document.getElementById('startBtn');
      const stopBtn = document.getElementById('stopBtn');
      const statusEl = document.getElementById('status');
      const endScreen = document.getElementById('end');
      const restartBtn = document.getElementById('restartBtn');
      const arLayer = document.getElementById('arLayer');
      const guide = document.getElementById('guide');
      const bgm = document.getElementById('bgm');

      let stream = null;
      let rafId = null;
      let scanning = false;
      let locked = false;
      let consecutiveHits = 0;

      async function startCamera(){
        try{
          stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: { ideal: "environment" } , width:{ideal:1280}, height:{ideal:720} },
            audio: false
          });
          video.srcObject = stream;
          await video.play();
        }catch(err){
          console.error(err);
          statusEl.textContent = "Camera permission denied or unavailable.";
        }
      }
      function stopCamera(){
        if(stream){
          stream.getTracks().forEach(t => t.stop());
          stream = null;
        }
      }

      // ---- Image detection (template matching with downsampling & NCC) ----
      const work = document.getElementById('work');
      const wctx = work.getContext('2d',{willReadFrequently:true});
      const tmpl = document.getElementById('tmpl');
      const tctx = tmpl.getContext('2d',{willReadFrequently:true});
      const refImg = document.getElementById('refImg');

      let tW = 120, tH = 160;  // template size (downscaled)
      let tVec = null, tMean = 0, tNorm = 1;

      function toGray(data){
        const out = new Float32Array((data.length/4)|0);
        for(let i=0,j=0;i<data.length;i+=4,j++){
          // luma
          out[j] = (0.299*data[i] + 0.587*data[i+1] + 0.114*data[i+2])/255;
        }
        return out;
      }
      function meanAndNorm(vec){
        let sum=0; for(let i=0;i<vec.length;i++) sum+=vec[i];
        const mean = sum/vec.length;
        let sq=0; for(let i=0;i<vec.length;i++){ const d=vec[i]-mean; sq+=d*d; }
        const norm = Math.sqrt(sq);
        return [mean, norm || 1];
      }
      function dotNCC(a, aMean, aNorm, b, bMean, bNorm){
        let s=0;
        for(let i=0;i<a.length;i++){
          s += (a[i]-aMean)*(b[i]-bMean);
        }
        return s/(aNorm*bNorm);
      }

      async function prepareTemplate(){
        await new Promise(res=>{
          if(refImg.complete) res(); else refImg.onload = res;
        });
        // Fit portrait-ish template
        const r = refImg.naturalHeight/refImg.naturalWidth;
        tH = Math.round(tW*r);
        tmpl.width = tW; tmpl.height = tH;
        tctx.drawImage(refImg, 0, 0, tW, tH);
        const tData = tctx.getImageData(0,0,tW,tH).data;
        tVec = toGray(tData);
        [tMean, tNorm] = meanAndNorm(tVec);
      }

      function findTarget(){
        // Resize frame for speed
        const vw = video.videoWidth || 1280;
        const vh = video.videoHeight || 720;
        const scale = 360 / Math.min(vw, vh);
        const fw = Math.round(vw*scale);
        const fh = Math.round(vh*scale);

        work.width = fw; work.height = fh;
        wctx.save();
        // Since video is mirrored with CSS, redraw mirrored so math matches screen
        wctx.translate(fw,0); wctx.scale(-1,1);
        wctx.drawImage(video, 0, 0, fw, fh);
        wctx.restore();

        const frame = wctx.getImageData(0,0,fw,fh);
        const fGray = toGray(frame.data);
        const winW = tW, winH = tH;

        let best = {score:-1, x:0, y:0, w:winW, h:winH};
        const step = 8; // slide step
        // Precompute window vec for each pos (naive, but OK at this scale)
        for(let y=0;y<=fh-winH; y+=step){
          for(let x=0;x<=fw-winW; x+=step){
            // Extract window
            const wVec = new Float32Array(winW*winH);
            let k=0;
            for(let yy=0;yy<winH;yy++){
              const rowStart = (y+yy)*fw + x;
              for(let xx=0;xx<winW;xx++){
                wVec[k++] = fGray[rowStart+xx];
              }
            }
            const [wMean, wNorm] = meanAndNorm(wVec);
            const s = dotNCC(wVec, wMean, wNorm, tVec, tMean, tNorm);
            if(s>best.score){ best={score:s, x, y, w:winW, h:winH}; }
          }
        }

        // Convert back to screen coordinates
        const screenW = video.clientWidth;
        const screenH = video.clientHeight;
        // Mapping from work canvas to video css box
        const rx = screenW/fw;
        const ry = screenH/fh;

        return {
          score: best.score,
          left: best.x*rx,
          top: best.y*ry,
          width: best.w*rx,
          height: best.h*ry
        };
      }

      function showSpark(x,y){
        const s=document.createElement('div');
        s.className='spark';
        s.style.left=(x-4)+'px';
        s.style.top=(y-4)+'px';
        s.style.position='absolute';
        document.body.appendChild(s);
        setTimeout(()=>s.remove(),800);
      }

      // ---- GIF decoding + 0.5x speed playback (using a tiny embedded GIF decoder) ----
      // Minimal omggif decoder (stripped to get frames + delays into RGBA).
      // Source: https://github.com/deanm/omggif (MIT). Inlined and compact for this use.
      // <CHANGE> Embedded lightweight GIF decoder to control playback rate for GIFs
      // BEGIN omggif (minimized essentials)
      (function(global){function l(a){this.data=a;this.pos=0}l.prototype.readByte=function(){return this.data[this.pos++]};l.prototype.readBytes=function(a){var b=this.data.subarray(this.pos,this.pos+a);this.pos+=a;return b};l.prototype.readUShort=function(){var a=this.data[this.pos++]|this.data[this.pos++]<<8;return a};l.prototype.readString=function(a){a=this.readBytes(a);var b="";for(var c=0;c<a.length;c++)b+=String.fromCharCode(a[c]);return b};function m(a){this.width=0;this.height=0;this.frames=[];this.bgColor=0;this.loopCount=null;this.parse(a)}m.prototype.parse=function(a){a=new l(new Uint8Array(a));if("GIF"!==a.readString(3))throw Error("Not a GIF file.");a.readString(3);this.width=a.readUShort();this.height=a.readUShort();var b=a.readByte(),c=(b&128)?1<<((b&7)+1):0;this.bgColor=a.readByte();a.readByte();var d=null;c&&(d=a.readBytes(3*c));for(;;){var e=a.readByte();if(33===e){e=a.readByte();if(249===e){a.readByte();var f=a.readByte(),g=a.readUShort();a.readByte();a.readByte();this._gce={disposal:(f>>2)&7,transIndex:null!==null?null:null,delay:g*10}}else if(255===e){var h=a.readByte();if(11===h){var k=a.readString(11);if("NETSCAPE2.0"===k){a.readByte();a.readByte();this.loopCount=a.readUShort();a.readByte() }else{for(;0!==a.readByte();)a.readBytes(a.readByte())}}else{a.readBytes(h);for(;0!==a.readByte();)a.readBytes(a.readByte())}}else{for(;0!==a.readByte();)a.readBytes(a.readByte())}}else if(44===e){var n={};n.x=a.readUShort();n.y=a.readUShort();n.w=a.readUShort();n.h=a.readUShort();var p=a.readByte();n.lct=(p&128)?1<<((p&7)+1):0;n.interlaced=!!(p&64);var q=n.lct?a.readBytes(3*n.lct):d;var r=a.readByte();var t=[],u=function(){var x=a.readByte();if(0===x)return null;return a.readBytes(x)};for(var v=u();null!==v;v=u())for(var y=0;y<v.length;y++)t.push(v[y]);n.pixels= w(new Uint8Array(t),r,n.w*n.h);n.delay=this._gce?this._gce.delay:100;this.frames.push({x:n.x,y:n.y,w:n.w,h:n.h,delay:n.delay,interlaced:n.interlaced,colors:q,pixels:n.pixels});this._gce=null}else if(59===e){break}else{throw Error("Unknown block: "+e);}}};function w(a,b,c){var d=1<<b;var e=d+1;var f=d+2;var g=null;var h=0;var k=0;var n=0;var p=0;var S=function(z,C){for(var D=0;D<C;D++){n|=a[p++]<<h;h+=8;for(;;){if(k<C){var E=n&(1<<b)-1;n>>=b;h-=b;C=k}break}}};var q=[];var r=[];for(var t=0;t<d;t++){q[t]=[];q[t].push(t);r[t]=t}var u=[],v=b+1,y=(1<<v)-1,A=f;var B=[];for(;;){if(p>=a.length)break;g=n&(1<<v)-1;n>>=v;h-=v;if(g===d){v=b+1;y=(1<<v)-1;A=f;u=[];continue}if(g===e)break;var F;if(g<A){F=q[g].slice(0)}else if(g===A&&u.length){F=u.slice(0);F.push(u[0])}else{continue}for(var G=0;G<F.length;G++)B.push(F[G]);if(u.length){q[A]=u.slice(0);q[A].push(F[0]);A++;if(A===1<<v&&v<12){v++;y=(1<<v)-1}}u=F}return B.slice(0,c)}
      function decodeGIFToCanvas(ctx, frame, palette){
        const {w,h,pixels} = frame;
        const img = ctx.createImageData(w,h);
        const data = img.data;
        for(let i=0;i<pixels.length;i++){
          const pi = pixels[i];
          const r = palette[3*pi], g = palette[3*pi+1], b = palette[3*pi+2];
          const j = i*4;
          data[j]=r; data[j+1]=g; data[j+2]=b; data[j+3]=255;
        }
        ctx.putImageData(img,0,0);
      }
      global._GIF = {GifReader:m, decodeGIFToCanvas};
      })(window);
      // END omggif

      // Wrapper class: play a GIF at 0.5x on a canvas
      class GifPlayer {
        constructor(canvas, url, playback=0.5){
          this.canvas = canvas;
          this.url = url;
          this.playback = playback; // 0.5x = slower
          this.ctx = canvas.getContext('2d');
          this.frames = [];
          this.pal = null;
          this.idx = 0;
          this.timer = null;
        }
        async load(){
          const res = await fetch(this.url);
          const buf = await res.arrayBuffer();
          const reader = new _GIF.GifReader(buf);
          // Use global palette per frame
          for(const fr of reader.frames){
            this.frames.push(fr);
            if(!this.pal) this.pal = fr.colors;
          }
          const w = this.frames[0].w, h = this.frames[0].h;
          this.canvas.width = w; this.canvas.height = h;
        }
        start(){
          const step = ()=>{
            const fr = this.frames[this.idx];
            _GIF.decodeGIFToCanvas(this.ctx, fr, this.pal);
            const delay = Math.max(20, fr.delay||100); // ms per frame
            const slowed = delay / (this.playback||1); // 0.5 => delay/0.5 = 2x slower
            this.idx = (this.idx+1)%this.frames.length;
            this.timer = setTimeout(step, slowed);
          };
          step();
        }
        stop(){ if(this.timer){ clearTimeout(this.timer); this.timer=null; } }
      }

      // ---- GIF players (three gifs) ----
      // Replace these paths with your .gif files (place them relative to index.html)
      const GIFS = [
        { id:'gif1', src:'1.gif' },
        { id:'gif2', src:'2.gif' },
        { id:'gif3', src:'3.gif' },
      ];
      const players = [];

      async function loadGifs(){
        // init players
        for(const g of GIFS){
          const cv = document.getElementById(g.id);
          const p = new GifPlayer(cv, g.src, 0.5);
          await p.load();
          players.push(p);
        }
      }
      function startGifs(){ players.forEach(p=>p.start()); }
      function stopGifs(){ players.forEach(p=>p.stop()); }

      // ---- AR Flow ----
      async function startAR(){
        sayWelcome();
        startBtn.style.display='none';
        stopBtn.style.display='inline-block';
        statusEl.textContent = "Initializing camera and audio...";
        await Promise.all([startCamera(), prepareTemplate(), loadGifs()]);
        statusEl.textContent = "Point your camera at the reference image.";
        guide.style.borderColor = 'rgba(14,165,233,.45)';

        // Play background music on user gesture
        try{ bgm.currentTime = 0; await bgm.play(); }catch(e){}
        bgm.onended = endAR;

        scanning = true;
        locked = false;
        scanLoop();
      }

      function scanLoop(){
        if(!scanning) return;
        const match = findTarget();
        // Update overlay position & lock if score strong
        if(match.score > 0.86){
          consecutiveHits++;
          // anchor overlay
          arLayer.style.transform = `translate(${match.left}px, ${match.top}px)`;
          arLayer.style.width = `${match.width}px`;
          arLayer.style.height = `${match.height}px`;
          if(!locked && consecutiveHits>=3){
            locked = true;
            arLayer.classList.add('active');
            startGifs();
            statusEl.textContent = "Target locked. Enjoy the experience.";
            // Sparkle
            showSpark(match.left+match.width/2, match.top+match.height/2);
          }
        }else{
          consecutiveHits = 0;
          if(!locked){
            arLayer.classList.remove('active');
          }
        }
        rafId = requestAnimationFrame(scanLoop);
      }

      function endAR(){
        scanning = false;
        cancelAnimationFrame(rafId);
        stopGifs();
        arLayer.classList.remove('active');
        stopBtn.style.display='none';
        endScreen.classList.add('show');
        statusEl.textContent = "Session ended.";
        stopCamera();
      }

      function stopAR(){
        try{ bgm.pause(); }catch(e){}
        endAR();
      }

      function restart(){
        endScreen.classList.remove('show');
        startBtn.style.display='inline-block';
        statusEl.textContent = "Tap Start to allow back camera + audio. Then point at the reference image.";
      }

      // ---- Bindings ----
      startBtn.addEventListener('click', startAR);
      stopBtn.addEventListener('click', stopAR);
      restartBtn.addEventListener('click', restart);

      // Prevent screen lock on mobile by keeping video playing; advise fullscreen
      document.addEventListener('visibilitychange', ()=>{
        if(document.visibilityState==='visible' && stream && video.paused){ video.play(); }
      }, {passive:true});
    </script>
  </body>
</html>